{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import json\n",
    "\n",
    "import pyspark\n",
    "import pyspark.ml.feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>list_transformers</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x11590e550>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.sql.SparkSession.builder.appName('list_transformers').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binarizer\n",
      "BucketedRandomProjectionLSH\n",
      "Bucketizer\n",
      "ChiSqSelector\n",
      "(\"Invalid transformer (doesn't have setInputCol or setInputCols): \", \"<class 'pyspark.ml.feature.ChiSqSelector'>\")\n",
      "CountVectorizer\n",
      "DCT\n",
      "ElementwiseProduct\n",
      "FeatureHasher\n",
      "HashingTF\n",
      "IDF\n",
      "Imputer\n",
      "IndexToString\n",
      "LSHParams\n",
      "(\"Invalid transformer (doesn't have setInputCol or setInputCols): \", \"<class 'pyspark.ml.feature.LSHParams'>\")\n",
      "MaxAbsScaler\n",
      "MinHashLSH\n",
      "MinMaxScaler\n",
      "NGram\n",
      "Normalizer\n",
      "OneHotEncoder\n",
      "OneHotEncoderEstimator\n",
      "PCA\n",
      "PolynomialExpansion\n",
      "QuantileDiscretizer\n",
      "RFormula\n",
      "(\"Invalid transformer (doesn't have setInputCol or setInputCols): \", \"<class 'pyspark.ml.feature.RFormula'>\")\n",
      "RegexTokenizer\n",
      "SQLTransformer\n",
      "(\"Invalid transformer (doesn't have setInputCol or setInputCols): \", \"<class 'pyspark.ml.feature.SQLTransformer'>\")\n",
      "StandardScaler\n",
      "StopWordsRemover\n",
      "StringIndexer\n",
      "Tokenizer\n",
      "VectorAssembler\n",
      "VectorIndexer\n",
      "VectorSizeHint\n",
      "VectorSlicer\n",
      "Word2Vec\n"
     ]
    }
   ],
   "source": [
    "import pipeasy_spark as ppz\n",
    "\n",
    "def isvalid(transformer):\n",
    "    try:\n",
    "        ppz.transformers.set_transformer_in_out(transformer, 'in', 'out')\n",
    "        return True\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "        return False\n",
    "\n",
    "not_tested = []\n",
    "valid_transformers = []\n",
    "invalid_transformers = []\n",
    "\n",
    "for name, obj in inspect.getmembers(pyspark.ml.feature):\n",
    "    \n",
    "    if inspect.getmodule(obj) == pyspark.ml.feature and inspect.isclass(obj):\n",
    "        if not issubclass(obj, pyspark.ml.feature.JavaModel):\n",
    "            \n",
    "            instance = obj()\n",
    "            description = {\n",
    "                'name': name,\n",
    "                # 'class': obj,\n",
    "                # 'instance': instance,\n",
    "                'parameters': list(inspect.signature(obj.__init__).parameters.keys())\n",
    "            }\n",
    "            description = name + str(inspect.signature(obj))\n",
    "            print(name)\n",
    "            if isvalid(instance):\n",
    "                valid_transformers.append(description)\n",
    "            else:\n",
    "                invalid_transformers.append(description)\n",
    "        else:\n",
    "            not_tested.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[pyspark.ml.feature.BucketedRandomProjectionLSHModel,\n",
       " pyspark.ml.feature.ChiSqSelectorModel,\n",
       " pyspark.ml.feature.CountVectorizerModel,\n",
       " pyspark.ml.feature.IDFModel,\n",
       " pyspark.ml.feature.ImputerModel,\n",
       " pyspark.ml.feature.LSHModel,\n",
       " pyspark.ml.feature.MaxAbsScalerModel,\n",
       " pyspark.ml.feature.MinHashLSHModel,\n",
       " pyspark.ml.feature.MinMaxScalerModel,\n",
       " pyspark.ml.feature.OneHotEncoderModel,\n",
       " pyspark.ml.feature.PCAModel,\n",
       " pyspark.ml.feature.RFormulaModel,\n",
       " pyspark.ml.feature.StandardScalerModel,\n",
       " pyspark.ml.feature.StringIndexerModel,\n",
       " pyspark.ml.feature.VectorIndexerModel,\n",
       " pyspark.ml.feature.Word2VecModel]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"Binarizer(threshold=0.0, inputCol=None, outputCol=None)\",\n",
      "    \"BucketedRandomProjectionLSH(inputCol=None, outputCol=None, seed=None, numHashTables=1, bucketLength=None)\",\n",
      "    \"Bucketizer(splits=None, inputCol=None, outputCol=None, handleInvalid='error')\",\n",
      "    \"CountVectorizer(minTF=1.0, minDF=1.0, vocabSize=262144, binary=False, inputCol=None, outputCol=None)\",\n",
      "    \"DCT(inverse=False, inputCol=None, outputCol=None)\",\n",
      "    \"ElementwiseProduct(scalingVec=None, inputCol=None, outputCol=None)\",\n",
      "    \"FeatureHasher(numFeatures=262144, inputCols=None, outputCol=None, categoricalCols=None)\",\n",
      "    \"HashingTF(numFeatures=262144, binary=False, inputCol=None, outputCol=None)\",\n",
      "    \"IDF(minDocFreq=0, inputCol=None, outputCol=None)\",\n",
      "    \"Imputer(strategy='mean', missingValue=nan, inputCols=None, outputCols=None)\",\n",
      "    \"IndexToString(inputCol=None, outputCol=None, labels=None)\",\n",
      "    \"MaxAbsScaler(inputCol=None, outputCol=None)\",\n",
      "    \"MinHashLSH(inputCol=None, outputCol=None, seed=None, numHashTables=1)\",\n",
      "    \"MinMaxScaler(min=0.0, max=1.0, inputCol=None, outputCol=None)\",\n",
      "    \"NGram(n=2, inputCol=None, outputCol=None)\",\n",
      "    \"Normalizer(p=2.0, inputCol=None, outputCol=None)\",\n",
      "    \"OneHotEncoder(dropLast=True, inputCol=None, outputCol=None)\",\n",
      "    \"OneHotEncoderEstimator(inputCols=None, outputCols=None, handleInvalid='error', dropLast=True)\",\n",
      "    \"PCA(k=None, inputCol=None, outputCol=None)\",\n",
      "    \"PolynomialExpansion(degree=2, inputCol=None, outputCol=None)\",\n",
      "    \"QuantileDiscretizer(numBuckets=2, inputCol=None, outputCol=None, relativeError=0.001, handleInvalid='error')\",\n",
      "    \"RegexTokenizer(minTokenLength=1, gaps=True, pattern='\\\\\\\\s+', inputCol=None, outputCol=None, toLowercase=True)\",\n",
      "    \"StandardScaler(withMean=False, withStd=True, inputCol=None, outputCol=None)\",\n",
      "    \"StopWordsRemover(inputCol=None, outputCol=None, stopWords=None, caseSensitive=False)\",\n",
      "    \"StringIndexer(inputCol=None, outputCol=None, handleInvalid='error', stringOrderType='frequencyDesc')\",\n",
      "    \"Tokenizer(inputCol=None, outputCol=None)\",\n",
      "    \"VectorAssembler(inputCols=None, outputCol=None)\",\n",
      "    \"VectorIndexer(maxCategories=20, inputCol=None, outputCol=None, handleInvalid='error')\",\n",
      "    \"VectorSizeHint(inputCol=None, size=None, handleInvalid='error')\",\n",
      "    \"VectorSlicer(inputCol=None, outputCol=None, indices=None, names=None)\",\n",
      "    \"Word2Vec(vectorSize=100, minCount=5, numPartitions=1, stepSize=0.025, maxIter=1, seed=None, inputCol=None, outputCol=None, windowSize=5, maxSentenceLength=1000)\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(valid_transformers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    \"ChiSqSelector(numTopFeatures=50, featuresCol='features', outputCol=None, labelCol='label', selectorType='numTopFeatures', percentile=0.1, fpr=0.05, fdr=0.05, fwe=0.05)\",\n",
      "    \"LSHParams()\",\n",
      "    \"RFormula(formula=None, featuresCol='features', labelCol='label', forceIndexLabel=False, stringIndexerOrderType='frequencyDesc', handleInvalid='error')\",\n",
      "    \"SQLTransformer(statement=None)\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(invalid_transformers, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
