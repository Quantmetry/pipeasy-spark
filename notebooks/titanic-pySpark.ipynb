{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:05:32.049931Z",
     "start_time": "2019-01-08T14:05:31.905506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjamin/Documents/Quantmetry_Missions/RetD/pipeasy-spark/.venv/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:05:42.405260Z",
     "start_time": "2019-01-08T14:05:33.697000Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a spark session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:05:42.449532Z",
     "start_time": "2019-01-08T14:05:42.432103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>titanic</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x114b7ef28>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data and exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:05:47.311504Z",
     "start_time": "2019-01-08T14:05:42.469216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "df = spark.read.csv('./datasets/titanic.csv', header=True, inferSchema=True, sep='\\t')\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:07.072665Z",
     "start_time": "2019-01-08T14:06:06.784830Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:08.264532Z",
     "start_time": "2019-01-08T14:06:08.124972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:09.868204Z",
     "start_time": "2019-01-08T14:06:09.430158Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable  value\n",
       "0   PassengerId      0\n",
       "1      Survived      0\n",
       "2        Pclass      0\n",
       "3          Name      0\n",
       "4           Sex      0\n",
       "5           Age     30\n",
       "6         SibSp      0\n",
       "7         Parch      0\n",
       "8        Ticket      0\n",
       "9          Fare      0\n",
       "10        Cabin    125\n",
       "11     Embarked      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Counting missing values\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "df.select(*(sum(col(c).isNull().cast('int')).alias(c) for c in df.columns)).toPandas().melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:13.648727Z",
     "start_time": "2019-01-08T14:06:11.910852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PassengerId</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Survived</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pclass</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Name</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sex</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SibSp</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Parch</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ticket</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fare</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Cabin</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Embarked</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       variable  value\n",
       "0   PassengerId    156\n",
       "1      Survived      2\n",
       "2        Pclass      3\n",
       "3          Name    156\n",
       "4           Sex      2\n",
       "5           Age     56\n",
       "6         SibSp      6\n",
       "7         Parch      5\n",
       "8        Ticket    145\n",
       "9          Fare     93\n",
       "10        Cabin     28\n",
       "11     Embarked      3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count of unique values\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "df.select(*(countDistinct(col(c)).alias(c) for c in df.columns)).toPandas().melt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:20.990598Z",
     "start_time": "2019-01-08T14:06:20.539272Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x120cad0b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "num_columns = [item[0] for item in df.drop(\n",
    "    'PassengerId').dtypes if not item[1] == 'string']\n",
    "corr_data = VectorAssembler(inputCols=num_columns, outputCol='features').transform(\n",
    "    df.dropna()).select('features')\n",
    "\n",
    "corr_mat = Correlation.corr(corr_data, 'features').toPandas()\n",
    "corr_mat = pd.DataFrame(corr_mat['pearson(features)'][0].toArray().astype(float),\n",
    "                        columns=num_columns,\n",
    "                        index=num_columns)\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "sns.heatmap(corr_mat, cmap=cmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limited example: output from dataframe-mapper (categorical & numerical transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:24.748519Z",
     "start_time": "2019-01-08T14:06:23.223791Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[3.723075040654779]</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>[1.5021431833972851]</td>\n",
       "      <td>[0.8813549847826144]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.1744835715812996]</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.241025013551593]</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>[2.5946109531407653]</td>\n",
       "      <td>[0.8813549847826144]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1.7155537624967245]</td>\n",
       "      <td>(0.0, 1.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[3.723075040654779]</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>[1.7752601258331553]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.1907285937630068]</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[1.241025013551593]</td>\n",
       "      <td>(0.0)</td>\n",
       "      <td>[2.389773246313863]</td>\n",
       "      <td>[0.8813549847826144]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[1.2779417449609667]</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[3.723075040654779]</td>\n",
       "      <td>(1.0)</td>\n",
       "      <td>[2.389773246313863]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.0]</td>\n",
       "      <td>[0.1937369312040637]</td>\n",
       "      <td>(1.0, 0.0)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived               Pclass    Sex                   Age  \\\n",
       "0         0  [3.723075040654779]  (1.0)  [1.5021431833972851]   \n",
       "1         1  [1.241025013551593]  (0.0)  [2.5946109531407653]   \n",
       "2         1  [3.723075040654779]  (0.0)  [1.7752601258331553]   \n",
       "3         1  [1.241025013551593]  (0.0)   [2.389773246313863]   \n",
       "4         0  [3.723075040654779]  (1.0)   [2.389773246313863]   \n",
       "\n",
       "                  SibSp  Parch                  Fare    Embarked  \n",
       "0  [0.8813549847826144]  [0.0]  [0.1744835715812996]  (1.0, 0.0)  \n",
       "1  [0.8813549847826144]  [0.0]  [1.7155537624967245]  (0.0, 1.0)  \n",
       "2                 [0.0]  [0.0]  [0.1907285937630068]  (1.0, 0.0)  \n",
       "3  [0.8813549847826144]  [0.0]  [1.2779417449609667]  (1.0, 0.0)  \n",
       "4                 [0.0]  [0.0]  [0.1937369312040637]  (1.0, 0.0)  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pipeasy_spark as ppz\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler, StandardScaler\n",
    "\n",
    "df_pipe = df.drop('PassengerId', 'Name', 'Ticket', 'Cabin').dropna()\n",
    "ppz_pipeline= ppz.build_pipeline_by_dtypes(\n",
    "    df_pipe,\n",
    "    exclude_columns=['Survived'],\n",
    "    string_transformers=[StringIndexer(), OneHotEncoderEstimator()],\n",
    "    numeric_transformers=[VectorAssembler(), StandardScaler()])\n",
    "ppz_model = ppz_pipeline.fit(df_pipe)\n",
    "df_pipe_out = ppz_model.transform(df_pipe)\n",
    "df_pipe_out.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full example: Training a random forest and defining the full pipeline (with ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:06:27.467112Z",
     "start_time": "2019-01-08T14:06:27.078114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# Random split into train/test\n",
    "train, test = df_pipe.randomSplit([.7,.3], seed=42)\n",
    "print(train.count())\n",
    "print(test.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-08T14:07:34.940105Z",
     "start_time": "2019-01-08T14:07:32.951731Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+\n",
      "|Survived|prediction|            features|\n",
      "+--------+----------+--------------------+\n",
      "|       0|       0.0|[1.28430485724300...|\n",
      "|       0|       0.0|[1.28430485724300...|\n",
      "|       0|       0.0|[1.28430485724300...|\n",
      "|       0|       0.0|[1.28430485724300...|\n",
      "|       0|       0.0|[1.28430485724300...|\n",
      "+--------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test AUROC = 0.8\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "preprocessing_pipeline = Pipeline(stages=[\n",
    "    ppz_pipeline,\n",
    "    # all the features are assembled in a single column\n",
    "    VectorAssembler(inputCols=['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'],\n",
    "                    outputCol='features')\n",
    "])\n",
    "# Train a RandomForest model.\n",
    "rf = RandomForestClassifier(labelCol=\"Survived\", \n",
    "                            featuresCol=\"features\", \n",
    "                            numTrees=5, \n",
    "                            seed=42)\n",
    "\n",
    "# Chain ppz_pipeline, rf and reverse label indexer\n",
    "pipeline = Pipeline(stages=[preprocessing_pipeline, rf])\n",
    "\n",
    "# Train model.\n",
    "model = pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"Survived\", \"prediction\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = BinaryClassificationEvaluator(\n",
    "    labelCol=\"Survived\", rawPredictionCol=\"prediction\", metricName=\"areaUnderROC\")\n",
    "AUROC = evaluator.evaluate(predictions)\n",
    "print(\"Test AUROC = {0}\".format(AUROC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
